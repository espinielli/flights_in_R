# Maps and geographic data {#maps}

[This chapter has been written out of sequence so might refer to patterns that have not yet been covered in earlier chapters.]

You don't get far in visualising patterns of air traffic without a map, whether that's a map of airports, of routes between airports, or of regions: countries or, more air-traffic-focused, blocks of airspace. In this chapter we'll build a set of tools for such things.

```{r, echo=FALSE}
knitr::kable(data.frame(syl=c("spatial features, `s2`, `rnaturalearthdata`, R&D Data Archive, `geom_sf`, `%<>%`, `st_transform`, `CRS` and more.")),
             col.names = c("In this chapter, you'll be introduced to:"))
library(magrittr)
suppressPackageStartupMessages(library(tidyverse)) # without lots of messages 
```

## Spatial features {#spatialFeatures}

We choose to use ['spatial features'](https://r-spatial.github.io/sf/) package `sf` as the main source of geographic functions since, of the several options, it feels most like an extension to the `tidyverse`. `sf` gives us, amongst other things:

* `sfc`: geographic columns for data tables and tibbles, to hold points, lines and polygons;
* `sf`: spatial features objects, which are data tables and tibbles that have a designated default 'geometry' `sfc` column;
* functions which access libraries of geographic operations, such as for distances, intersections or unions;
* use of `geom_sf()` in a `ggplot` to plot one of these columns.

We'll shortly see an example, but a 'typical' `sf`-enriched dataframe might be have one row per flight and an `sfc` column which contains the route flown by the flight, in longitude-latitude but all folded up in a single cell per flight. There is lots of [good documentation](https://r-spatial.github.io/sf/) for 'spatial features' and plenty of good questions on StackExchange to help you with problems. There's even [a 'cheatsheet'](https://r-spatial.github.io/sf/#cheatsheet). Here we focus on _using_ `sf` with aviation data.

That use of supporting libraries can create complexity, for example requiring installation of extra code, such as `GDAL` (you'll see GDAL and other libraries mentioned when you attach sf in the next code chunk). We'll mostly stick to the `s2` library, for a number of reasons:

* the code is available directly as the `s2` package, so installation problems should be few;
* we can quickly translate between `s2` and `sf`;
* and `s2` works directly on the sphere.

```{r}
library(sf)
sf::sf_use_s2(TRUE) 
library(s2) # we use a number of functions directly from s2
library(rnaturalearthdata) # for country maps
```

What does that mean 'works directly on the sphere'? The main difference between geographic data and the sorts of data that we've been plotting so far is that the two dimensions, longitude and latitude, are not points on a plane, but on a sphere. One approach to working with such data is to map all your data onto the plane by transforming with a 'coordinate reference system' (CRS), and then work on the plane, allowing for some of the distortion that is inevitable, eg straight lines might no longer be straight.

With `s2` we work on the sphere itself, and transform only when we want to plot. I like the cleanliness of keeping CRS for plotting. There are some costs: in particular, the World isn't actually spherical, so there are some errors in [distance and area calculations](https://r-spatial.github.io/sf/articles/sf7.html#measures) for example. If your application is sensitive to distance errors of 0.5%, then other functions can be used.

Switch `sf` to using `s2` with `sf_use_s2(TRUE)` whenever you attach `library(sf)`, as we did at the start of this chapter. Then `sf` will use `s2` versions of functions whenever it can without further intervention from you.

What does `sf` give us? Here's an example, using `rnaturalearthdata`, a package that handily provides country maps. After converting the map data to `sf` with `st_as_sf()`, we have one row of a dataframe (an `sf` object is still a `dataframe`) per country, and all the map polygons in a single column. We illustrate the use of `filter()` on text fields, in a manner that you've seen before, and then with a 'logical' function that tests for intersection between `geometry` which contains the map polygons, and our `Dublin_Bucharest` line. 

```{r}
# a line from Dublin to Athens
Dublin_Bucharest <- st_linestring(matrix(c(-6.27, 53.42, 26.1, 44.57), 
                                         ncol = 2, byrow = TRUE)) %>% 
  # tell sf that it's in long-lat, EPSG4326 is a long-lat coordinate reference system
  st_sfc(crs = 4326)

# a map demo - countries110 comes with lots of data such as population
europe_countries <- rnaturalearthdata::countries110 %>% 
  st_as_sf() %>% # convert to sf
  # some of the polygons in the map cause issues so we zoom in
  # using metadata in the 'rnaturalearthdata' dataframe
  filter(admin != "Russia" & continent == "Europe") %>%
  # now do the intersection - working on the sphere
  # sparse = FALSE is required to get a full-length logical vector 
  #    rather than a vector of row ids
  # st_intersects  is a yes-no question
  filter(st_intersects(geometry, Dublin_Bucharest, sparse = FALSE)) %>% 
  # st_intersection asks for the intersection of the two
  mutate(segment = st_intersection(Dublin_Bucharest, geometry))

# simplest of plots treats long-lat like x-y
ggplot(europe_countries) +
  geom_sf(aes(fill = 1000 * gdp_md_est/pop_est)) +
  geom_sf(aes(geometry = segment), colour = "white") +
  labs(fill = "GDP\nPer Capita\n($ 000)",
       caption = "Simplified map omits many islands.")
```

In this one example, we see two geographical functions for intersection, `st_intersects()` and `st_intersection()`, and we see a line defined by just two points (as it should be, speaking geometrically) but showing as a curve when plotted on a rectilinear longitude-latitude grid (ie one with horizontal latitude lines and vertical longitudes). This demonstrates the line being a 'great circle'^[Strictly speaking, when we say 'great circle' in this book we really mean 'segment of a great circle', or 'along a great circle']. 

We cover country maps in more detail in section \@ref(mapCountries).
 
### Map Exercises

#### Questions

1) What does the map look like of those European countries _not_ overflown?
2) Which countries are within 100km of the route?
3) Before converting to `sf`, what's the structure of the data in `countries110`?
4) Add the Dublin-Bucharest line directly, with `geom_sf(data = Dublin_Bucharest)`. What's wrong and what do you think is the problem?

#### Answers

1) Wrap a `!( )` around the filter and see. Svalbard looks big in this plot, and the map opens up to show French Guiana.
2) Three additional States. Checking through the `s2` package documentation, we need `s2_dwithin()` (not `s2_within`), so use `s2::s2_dwithin(Dublin_Bucharest, 100 * 1000)`, since distances are in metres. 
3) Run just the first line and we get a `SpatialPolygonsDataFrame` which is actually a data frame plus some other elements. It's based on an alternative way of handling spatial data (`sp`), which we won't be using here mostly because it feels less 'tidyverse'.
4) The line is shown by ggplot as a straight line on the plot, because `ggplot` joins points with straight lines. At present, `geom_sf()` doesn't really understand great circles. Indeed, if you're sharp-eyed you might see that the 'great circle' already shown is actually made up of straight segments in each country. We'll see how to handle this later, but for the moment the lesson is: `sf` understands great circles, `ggplot` less so.

## Using the R&D Data Archive {#RnDArchive}

At this point, we'll start using data from the [EUROCONTROL R&D Data Archive](https://www.eurocontrol.int/dashboard/rnd-data-archive) which, at the time of writing, provides fine-grained data on some 14 million European flights between 2015 and 2019, with more data added each quarter. With a business or academic email address you can ask for free access to this. 

### Flight Summaries

Rather than clog up your hard-disk with data, start by just downloading some flight summaries, say for March 2019. The image below shows a step in this process. Check and accept the terms and conditions and you'll get your file.

![Downloading flight summary data for one quarter](images/RDArchive_download.png)

Save the data in your project `/data` folder, then the following code will work. You can leave the file with its `.csv.gz` extension; R can handle this. (The terms & conditions mean that the data cannot be bundled with this book.)

The 'Flights' file contains one row per flight, and gives a range of data about that flight, including departure and destination airports (ADEP, ADES), planned and actual times, aircraft type, aircraft operator etc. [See the documentation 'metadata'](https://www.eurocontrol.int/publication/rnd-data-archive-structure-and-sample) for more details.

The column names aren't very R-friendly, though. So we use a function to read the file and rename the columns. It takes a little while to load nearly 800,000 flights. 

```{r message = FALSE}
get_flights <- function(file_name){
  # load Flights...csv.gz file downloaded from R&D Data Archive
  readr::read_csv(file_name, skip = 1, 
                  col_names = c("id", "adep", "adep_lat", "adep_long", 
                                "ades", "ades_lat", "ades_long", 
                                "obt_filed", "arr_filed", "obt_actual", "arr_actual",
                                "ac_type", "ao", "ac_reg", 
                                "flt_type", "segment", "rfl", "dist_act_nm")) %>% 
    mutate_at(vars("obt_filed", "arr_filed", "obt_actual", "arr_actual"), 
              ~ as.POSIXct(., format = "%d-%m-%Y %H:%M:%S", tz = "UTC")) %>% 
    mutate(dist_act_km = 1.852 * dist_act_nm) %>% 
    select(-dist_act_nm)
}

flights <- get_flights("data/Flights_20190301_20190331.csv.gz")
```

It's good to do a visual check of numbers to see what we have. We take the day part of the filed off-blocks time (the time in the flight plan for push-back from the gate). We saw previously that this needs to be `floor_date` not `round_date` to get the start of the day. There are about 25,000 flights per day, although at this time of year Saturdays are significantly quieter.

```{r}
ggplot(flights,
       aes(lubridate::floor_date(obt_filed, "day"),
           fill = segment)) + 
  geom_bar() +
  labs(x = "Date (of filed off-blocks time)", 
       y = "Number of Commercial Flights in Sample") 
```

### Airspace structure {#airspaceData}

The structure of the airspace is continually refined to align with traffic needs. There are updates for each 'AIRAC cycle' which lasts 4 weeks. The R&D Data Archive provides airspace data for each applicable AIRAC cycle, and the smallest file in each quarter's data is `AIRAC_xxxx.csv.gz` which lists the AIRAC cycles and their dates during that month. 

The airspace structure is then given in terms of:

* the boundaries and vertical extent of each flight information region (FIR) structure (with a simplified structure outside Europe);
* the route network.

In this section we load and inspect the FIR data. From the 201903 archive, download the `FIR_1904.csv.gz` file and put it in your `data` folder. We need to do a little work with the data.

In the country data we saw briefly earlier, countries are described with 'multipolygons', each polygon being a ring that joins up and the 'multi' bit because there can be islands or, occasionally, holes (Italy has 2 holes, for the Vatican and San Marino). FIRs are no different. Most are single polygons, one or two have holes, and some have been split in these data along the dateline. We have to identify the rings, which we do here by looking for repeated coordinates (which are the two ends `(n() > 1)`), then finding the first end and flagging it with a `1`. A cumulative sum of these flags gives distinct ids to each ring.

One respect in which FIRs are different from countries is that they have a vertical extent and can overlap if you ignore altitude. We treat combinations of `airspace_id, min_flight_level, max_flight_level` as determining an FIR which isn't really true (an FIR can be thick in places and thin in others), but this will be enough for the moment.

```{r message=FALSE}
fir <- readr::read_csv("data/FIR_1904.csv.gz")
# tidy the column names
# this uses the 'and assign' pipe %<>%, for brevity
colnames(fir) %<>%
  stringr::str_replace_all("\\s", "_") %<>%
  stringr::str_to_lower()

fir_poly <- fir %>% 
  group_by(airspace_id, min_flight_level, max_flight_level, 
           longitude, latitude) %>% 
  mutate(ring_end = (n() > 1)) %>% # end points occur twice 
  ungroup(longitude, latitude) %>% 
  mutate(ring_start = if_else(ring_end &
                                (is.na(lag(ring_end)) | lag(ring_end)), 
                              1L, 0L), 
         ring_id = cumsum(ring_start)) %>% 
  select(-ring_end, -ring_start) %>% 
  # now make the polygon (with holes if that makes sense) 
  summarise(geo = s2::s2_make_polygon(longitude, latitude, ring_id = ring_id) %>% 
            sf::st_as_sfc()) %>% 
  # turn into sf object
  sf::st_set_geometry("geo") %>%
  ungroup()
```

A quick map highlights a number of features of the data: we just have large regions in places distant from Europe, aggregates of actual FIRS; the 'layers' of superimposed FIRs are less transparent so mask the underlying countries more, eg Spain, though this isn't a great way to show this; being Europe-oriented the data have been cut at 180º, to avoid wrapping problems (in fact the map is cut at 180° and the FIRs at 179°).

```{r}
ggplot(rnaturalearthdata::countries110 %>% st_as_sf()) +
  geom_sf(fill = "grey50") + 
  geom_sf(data = fir_poly, alpha = 0.7) 
```

This isn't very pretty. We'll look at a better version in section \@ref(mapAirspace).

### Flight profiles

The R&D Data Archive provides both the route from the filed flight plan, and the route as flown, updated by radar. Each route is specified as longitude-latitude points, a flight level (roughly of 100 feet, so FL350 = 35,000 feet altitude), and a time.

We will load and plot some profiles in section \@ref(trueRoutes).

### Exercises

#### Questions 

1) Download a second flight file. How would you automatically load and merge all of the flight files that you've downloaded. (Hint: This is a simplified version of something you did with files from the STATFOR dashboard in section \@ref(loadMultipleFiles).
2) Why did this involve switching from `pmap`?

#### Answers

1) This is it.

```{r eval=FALSE}
#get file names, with path
flight_files <- dir("data", pattern = "Flights_", full.names = TRUE)

# and load
all_flights <- flight_files %>% 
  map(get_flights) %>% 
  bind_rows()
```

2) Because the 'SID' code in the earlier chapter is reading a number of columns from a dataframe it uses `pmap`. Here we just have a single vector of names, so only need `map`.

## Countries and regions {#mapRegions}

In this section, we introduce work patterns for plotting countries or regions. We stick to the over-arching pattern of: keep the data in longitude-latitude, then transform when plotting into a coordinate reference system (CRS) chosen to suit the map.

### Countries {#mapCountries}

We already saw a country map in section \@ref(spatialFeatures). Let's take a step back and approach some of the key elements of plotting countries at a more steady pace: filtering, plotting, transforming, cropping.

It might be that you have a specific set of countries in mind. Then it's natural to do this by filtering the dataframe as you would with a non-geographic dataframe. While you might filter by name, it's more compact and often easier (due to alternative spellings of country names) to use the ISO code. The 1:110 million scale map in `countries110`, however, isn't great when we zoom in to this detail (for example it misses out many islands), so we use a 1:50 million map `countries50`. An even finer-grained, 1:10 million map is available, but not through CRAN, in the package `rnaturalearthhires`, while other European maps are available for example from Eurostat.

While we filter on the code `iso_a2` for the reasons discussed earlier, we use the `admin` field for the colour fill, since this creates a more informative legend, showing the administrative names.

```{r}
iberia_iso2 <- c("ES", "PT")
iberia <- rnaturalearthdata::countries50 %>% 
  st_as_sf() %>% 
  filter(iso_a2 %in% iberia_iso2)

# colour by country, make the borders thin.
ggplot(iberia) + geom_sf(aes(fill = admin), size = 0.1) +
  labs(fill = "Country") + 
  theme_minimal()
```

There's something a little ugly about this map - the shapes are distorted because we aren't doing any sort of projection but just plotting longitude and latitude as if they were x-y coordinates. We could transform the data (the `sf` or the `geometry` column) to a new CRS, but because we're working with `s2`, on the sphere in long-lat, it makes sense to keep our data in long-lat, and transform only for the purpose of plotting. 

The easiest way to do that is to add a `coord_sf(crs = xx)` to the plot, which ensures all of the layers (if we have more than one layer) are in the same CRS. For Europe maps, EPSG3035 is often recommended for statistical charts: it's a Lambert Equal Area transformation set up for Europe. So here we just add `coord_sf(crs = 3035)`.

```{r}
use_crs <- 3035
# use ggplot::last_plot() rather than repeat the code
last_plot() +
  # apply the transform
  coord_sf(crs = use_crs)
```

What if we want a map without Canaries or Azores, but with Madeira, say? With some sets of maps, the parts of countries are separate so can be filtered by name. In the `rnaturalearth` dataframe they are not. We need to crop the map. Again, this is about the map, not the data, so rather than cropping the data, we basically need to set limits to the plot. 

The catch is that we need to do this in the units of the projection (EPSG3035) which, after the transformation, is metres. We probably want to crop in terms of degrees. So we create some points (in degrees) and transform them, too, to get the values in metres. Because of the projections, the window is a different width at top and bottom, in degrees: think in terms of what point should be in the bottom left corner, and what in the top right. Fiddly, but it works. We'll shortly see how to crop automatically based on the data, but it's useful to know the bottom-left/top-right rule.

```{r}
#set limits at long-lat (-20, 30) to (5, 45)
lim_corners <- st_multipoint(matrix(c(-20, 30, 5, 45), ncol = 2, byrow = TRUE)) %>% 
  st_sfc(crs = 4326) %>% #create the points in long-lat
  #then transform to the map CRS then pull out a 
  #   matrix of values (with named columns X and Y)
  st_transform(use_crs) %>% 
  st_coordinates()

last_plot() +
  # apply the transform
  coord_sf(xlim = c(lim_corners[1, "X"], lim_corners[2, "X"]), 
           ylim = c(lim_corners[1, "Y"], lim_corners[2, "Y"]),
           crs = use_crs)
```

### Airspace {#mapAirspace}

In section \@ref(airspaceData) we made a quick check of the FIRs with a map. Here we make a tidier map.

When plotting the whole World, the default map projection makes even worse distortions than we saw for Iberia. We would like to use a better representation of the area of countries, but need to handle the problem seen in the exercises in section \@ref(spatialFeatures): that `ggplot` just draws straight lines. In the R&D data, some of the FIRs distant from Europe are described with a minimum of points, such as a straight line from (179, 0) to (179, 90). We solve the problem by adding extra points at an arbitrary 1° interval using `st_segmentize()`. 

This example illustrates a strength of an `sf` dataframe. It can contain many `sfc` columns, but one is the designated geometry. We can then apply a function such as `st_segmentize` to the whole dataframe and it will pick out the geometry column to work with, where that's appropriate.

The Lambert (EPSG3035) projection also distorts on the whole-World scale. Instead, we choose an Atlantic-centred Robinson projection, creating it from a standardised text string using `sp::CRS`. 

XKCD suggests this [reveals something of my age](https://xkcd.com/977/) and indeed, it's a familiar projection from school atlases. This CRS is also available as `himach::crs_Atlantic`, if you have that package installed. 

And finally we colour code the upper flight level of the FIR - so the darker blue areas are lower FIRs.

```{r}
crs_robinson <- sp::CRS("+proj=robin +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs +towgs84=0,0,0")
ggplot(rnaturalearthdata::countries110 %>% 
         st_as_sf()) +
  geom_sf(fill = "grey50") + 
  geom_sf(data = fir_poly %>% 
            st_segmentize(units::set_units(1, degree)), 
          aes(fill = max_flight_level), alpha = 0.6) +
  labs(fill = "Upper Flight Level of FIR") +
  coord_sf(crs = crs_robinson) +
  theme_minimal() + theme(legend.position = "bottom")
```

If we want to zoom in to Europe, which is where most of the flight data is, it is tempting to filter on the FIR airspace ID, though this harder than just picking those starting with 'E', 'L' or 'B', eg what about the Canary Islands, or Ukraine? It is probably best to avoid this approach unless you have a very specific list of countries to include.   

As in the previous section, instead we set the limits of the plot using the 'bottom-left, top-right and transform' method.

```{r}
use_crs <- crs_robinson
#set limits at long-lat (-20, 30) to (50, 80)
lim_corners <- st_multipoint(matrix(c(-20, 25, 70, 80), ncol = 2, byrow = 2)) %>% 
  st_sfc(crs = 4326) %>% 
  #transform then pull out a matrix of values (with named columns X and Y)
  st_transform(use_crs) %>% 
  st_coordinates()

ggplot(rnaturalearthdata::countries50 %>% 
         st_as_sf()) +
  geom_sf(fill = "grey50") + # background colour for the land
  geom_sf(data = fir_poly %>% 
            st_segmentize(units::set_units(1, degree)), 
          aes(fill = max_flight_level), alpha = 0.6) +
  labs(fill = "Upper\nFlight Level\nof FIR") +
  coord_sf(crs = use_crs, 
           xlim = c(lim_corners[1, "X"], lim_corners[2, "X"]), 
           ylim = c(lim_corners[1, "Y"], lim_corners[2, "Y"])) +
  theme_minimal()
```

As a plot of a 3D-layered structure this still misses something, but it's not bad to get an idea of the airspace structure and where there are layers. 

What about labels? For this we just need to define the label text, which we do by extracting just the 4-letter FIR codes, excluding the "FIR" and "UIR". Chapter \@ref(splitparse) has much more on patterns such as `"FIR|UIR"`. The `geom_sf_text` will be put at the centroid of the polygon by default. We'll see how to deconflict labels on maps in section \@ref(mapOverlapLabels).

```{r}
fir_poly <- fir_poly %>% 
  mutate(airspace = stringr::str_remove(airspace_id, "(UIR|FIR)(S|N)?")) %>% 
  group_by(airspace) %>% 
  mutate(label = if_else(max_flight_level == max(max_flight_level),
                         airspace, ""))

ggplot(fir_poly %>% 
         st_segmentize(units::set_units(1, degree))) +
  geom_sf(data = rnaturalearthdata::countries50 %>% 
            st_as_sf(),
          fill = "grey50") + # background colour for the land
  geom_sf(alpha = 0.6) +
  geom_sf_text(aes(label = label), size = 1.8) +
  coord_sf(crs = use_crs, 
           xlim = c(lim_corners[1, "X"], lim_corners[2, "X"]), 
           ylim = c(lim_corners[1, "Y"], lim_corners[2, "Y"])) +
  theme_minimal()
```


### Exercises

#### Questions

1) In the final map, adapt the code so that it will plot a slice at a particular flight level, and use an appropriate title.
2) One messy part of the FIR map is GCCC, which has overlapping labels for GCCCUIRS and GCCCUIRN. How could we clean this up?
3) In the two versions of the code for the FIR map, why do we swap where `fir_poly` and `countries50` are mentioned (`ggplot` and `geom_sf`)?

#### Answers

1) We can filter, and then use the original label. So one solution is as follows.

```{r}
at_fl <- 350
fir_slice <- fir_poly %>% 
  # max of lower = min of upper, so we arbitrarily put the boundary in the lower
  filter(min_flight_level < at_fl & at_fl <= max_flight_level)

ggplot(fir_slice %>% 
         st_segmentize(units::set_units(1, degree))) +
  geom_sf(data = rnaturalearthdata::countries50 %>% 
            st_as_sf(),
          fill = "grey50") + # background colour for the land
  geom_sf(alpha = 0.6) +
  geom_sf_text(aes(label = airspace_id), size = 1.8) +
  labs(x = "", y = "",
       title = stringr::str_c("FIR/UIRs at flight level ", at_fl)) +
  coord_sf(crs = use_crs, 
           xlim = c(lim_corners[1, "X"], lim_corners[2, "X"]), 
           ylim = c(lim_corners[1, "Y"], lim_corners[2, "Y"])) +
  theme_minimal()
```

2) A pattern which allows for an optional "S" or "N" would be "(UIR|FIR)(S|N)?".
3) In the first map it didn't really matter, but the countries are the first layer so they were put first. In the second, we want the `fir_poly` to be the default data for the additional `geom_sf_text`, so it has to be the one inside the `ggplot`.

## Airports {#mapAirports}

In this section we look at plotting airports. Much of it is assembling techniques we've already seen: plotting points with `geom_point` in chapter \@ref(firstLook) and elsewhere; map layers from earlier in this chapter. New ideas will include: preferring to plot densities rather than simple counts; and how to de-conflict labels on maps.

As a warm up, let's plot the busiest airports for one market segment; use `unique(flights$segment)` to get a list of all that are available in the data. Still scope for something new: we see a quick way to convert two columns (longitude, latitude) into a spatial feature column, another use of `st_as_sf()`; and we work out the bounding box automatically, using `st_bbox()` and also `st_buffer()` so as not to have airports too close to the edge of the map.

```{r}
# to avoid repeating ourselves with the background map
geom_sf_bg <- function( ..., m = rnaturalearthdata::countries50,
                       fill = "grey80", colour = "white", size = 0.1) {
  geom_sf(..., data = m %>% st_as_sfc, 
          fill = fill, colour = colour, size = size)
}

# and to get bounding box for an sf, in plot coordinates
get_bounds <- function(sft, crs = 3035, margin_km = 100){
  sft %>% 
    st_transform(crs) %>% # convert to metres (TBD check if units are metres)
    st_buffer(margin_km * 1000) %>%  # add the buffer
    st_bbox() # get the bounding box for the selected airports
}

crs_europe <- 3035 #EPSG3035 is our good CRS for Europe maps
busiest_n <- 20
show_segment <- "Business Aviation"
busy_ap <- flights %>% 
  filter(segment == show_segment) %>% 
  # the data are one row per flight, so we need to count rows
  # keep just 3 columns and sort largest to smallest
  count(adep, adep_lat, adep_long, sort = TRUE) %>% 
  slice(1:busiest_n) %>% 
  # convert to sf, noting that long and lat are in degrees (EPSG4326)
  st_as_sf(coords = c("adep_long", "adep_lat"), crs = 4326)

bounds <- get_bounds(busy_ap)
  
ggplot(busy_ap) +
  geom_sf_bg() + #default background map
  geom_sf(aes(size = n), alpha = 0.6) +
  labs(size = "Number of\ndepartures",
       title = stringr::str_c(show_segment, " in March 2019."),
       caption = stringr::str_c("Top ", busiest_n, " airports are shown.")) +
  coord_sf(crs = crs_europe,
           xlim = c(bounds$xmin, bounds$xmax),
           ylim = c(bounds$ymin, bounds$ymax)) +
  theme_minimal()
```

### Overlapping labels on maps {#mapOverlapLabels}

We could label the maps with the airport codes in the same way that we did with the FIRs [try this], but the labels are overlapping. What function did we use in chapter \@ref(filter) to solve this problem? [try this, too]

The problem is that `ggrepel::geom_text_repel()` doesn't immediately understand the geometry column in our `busy_ap` data. Happily, a little googling comes to our aid: there is a way to get `geom_text_repel` still to do the work for us and convert what we do have, a `geometry`, into the x and y that it needs. All it takes is to use the additional parameter `stat = "sf_coordinates"`.

```{r}
last_plot() + # assumes you didn't actually do the 2 little exercises in [ ]
  ggrepel::geom_text_repel(aes(geometry = geometry, label = adep), 
                           stat = "sf_coordinates",
                           size = 1.8) 
```

## Routes {#mapRoutes}

The routes or aircraft are typically shown as either:

- a great circle joining the departure and destination airports;
- or a sequence of short line segments (which should be great circles) joining points along the actual route flown, where the points come from radar or other surveillance.

In this section we will see examples of each of these.

### Great Circle Routes

We saw in section \@ref(spatialFeatures) that `geom_sf` doesn't give us great circles by default, but joins with a straight line. There are two ways to get around this: use a CRS in which great circles map to straight lines, and our go-to CRS, EPSG3035, for Europe more-or-less has this nice property, as does the Lambert Conformal Conic (such as EPSG9040 for Europe) that is often used for aeronautical maps; alternatively, add intermediate points before plotting.

Which you choose depends on how important the routing is. A great-circle is often already 'schematic': just a way to link airports, rather than being too fussy about the intermediate points. But if you think the viewer will jump to conclusions about traffic density in the airspace, then best to use something more precise.

In the first example, we pick low-cost routes, which are mostly short- or medium-haul because this keeps the map mostly in Europe and therefore with less distortion (though Cuba in this map looks like it's been on a diet, not to mention being rotated to a confusing angle). We use the Lambert equal area projection, which we saved as `crs_europe` and take the simpler approach of plotting straight lines. 

We stick to the principle of keeping the data in longitude-latitude, then transform when plotting into a coordinate reference system (CRS). But there's still some manipulation of the data to do: for each row (`rowwise()` is a particular sort of `group_by` that works row by row) create a line, make it suitable for use in a dataframe (`st_sfc`) and tell `sf` that the CRS is long-lat (`crs=4326`).

```{r}
set.seed(380) # to get a fixed, but random sample
lcc_sample <- flights %>% 
  # just short- or medium-haul lowcost
  filter(segment == "Lowcost") %>% 
  slice_sample(n = 100) %>% #just pick a few for this example
  rowwise() %>% # we want to have one line per row of data
  mutate(gc = st_linestring(matrix(c(adep_long, ades_long, adep_lat, ades_lat), ncol = 2)) %>% 
           st_sfc(crs = 4326)) %>% 
  ungroup() %>%
  st_set_geometry("gc") 

#bounds doesn't mind if the sf geometry is points, lines, ... 
bounds <- get_bounds(lcc_sample) 
ggplot(lcc_sample) +
  geom_sf_bg() +
  geom_sf(alpha = 0.3)  +
  labs(title = "Sample of Low Cost routes") +
  coord_sf(crs = crs_europe,
           xlim = c(bounds$xmin, bounds$xmax),
           ylim = c(bounds$ymin, bounds$ymax)) +
  theme_minimal()
```

In the second example, we use a sample of longer-haul routes and the Robinson CRS. Construction of the data is the same, apart from the `filter`. But we need to specify a non-default crs in our `bounds` function. The work of adding extra points to each line is done with the `st_segmentize`, which conveniently we can apply to the whole data frame (as mentioned, it picks out the geometry column automatically for segmentation). You can adapt the step of the segments in degrees or km, appropriate to your target map. More looks nicer, but it takes up space, and takes time to plot.

```{r}
set.seed(777) # to get a fixed, but random sample
long_sample <- flights %>% 
  filter(dist_act_km > 4000) %>% 
  slice_sample(n = 100) %>% #just pick a few for this example
  rowwise() %>% # we want to have one line per row of data
  mutate(gc = st_linestring(matrix(c(adep_long, ades_long, adep_lat, ades_lat),
                                   ncol = 2)) %>% 
           st_sfc(crs = 4326)) %>% 
  ungroup() %>%
  st_set_geometry("gc") 

#bounds doesn't mind if the sf geometry is points, lines, ... 
bounds <- get_bounds(long_sample, 
                     crs = crs_robinson) 
ggplot(long_sample %>% 
  st_segmentize(units::set_units(1, degree)) ) +
  geom_sf_bg() +
  geom_sf(alpha = 0.3)  +
  labs(title = "Sample of long-haul routes") +
  coord_sf(crs = crs_robinson,
           xlim = c(bounds$xmin, bounds$xmax),
           ylim = c(bounds$ymin, bounds$ymax)) +
  theme_minimal()
```

### Need for Speed {#fasterGeo}

[This is an advanced section that uses quickly some packages that have not been introduced. But the gains in speed are considerable.]

We've been using small samples of data so far. Any larger and there will be a noticeable delay in converting from long-lat to spatial features, unless you're very lucky in your hardware. In this section we discuss two ways to speed things up: an easy one, and a fiddly one.

The easy speed-up is to avoid geo-coding the same route twice: the same airport pair is likely to occur several times in a large dataset: there are 767 occurrences of Madrid-Barcelona (LEMD-LEBL) for example. If we're only looking at great circle, then all of these routes are the same. Even with filtering and grouping for the statistics you're calculating (by aircraft type, by market segment etc), there's still going to be duplication, unless you really need the precise time (which is unlikely since it's tricky to show on a map). So best to `group_by` the variables you need to keep (including `adep_long, ades_long, adep_lat, ades_lat`) and summarise (see section \@ref(summarise)), taking a flight count [what code would that use?]. Only then convert to `sf` with `st_linestring` and friends.

The fiddly method is less obvious because it depends on developing a feel for what works quickly and what less quickly in R.

To my mind, using `rowwise` feels like I've failed. I might not have written `for...next`, but in effect, I've fallen back onto a for-next loop over each row in turn. I'm left believing I've missed a neat `tidyverse` solution, even if I'm being unfair and there might not be a neater alternative. The `rowwise` we used earlier is an example where there _is_ a more efficient way to code. This isn't just linguistic prejudice against `for...next`. Calling a function, here `st_linestring`, takes time, so calling it for each of 800,000 rows one-by-one in the flight data is going to be time-consuming. 

There is an interesting discussion of the conversion to [great circles here](https://www.findingyourway.io/blog/2018/02/28/2018-02-28_great-circles-with-sf-and-leaflet/). The solution is based on the `purrr` package that we saw in chapter \@ref(loopsfunctions). Instead of grouping (each row separately), it creates a list of lists - one list per row and that list contains the 4 longitude-latitude numbers. We saw `map` in chapter \@ref(loopsfunctions) as an efficient way to operate on each element of a list.

In this code chunk, we set up two parallel ways of coding the same thing. The `identical` test shows that the two results are the same. The `microbenchmark` shows, over 10 iterations of each, that the `purrr` approach is almost 15 times faster.

```{r}
library(microbenchmark)
flts <- set.seed(777) # to get a fixed, but random sample
long_sample <- flights %>% 
  filter(dist_act_km > 4000) %>% 
  slice_sample(n = 100) 

# adapted from Charlie Hadley https://www.findingyourway.io/blog/2018/02/28/2018-02-28_great-circles-with-sf-and-leaflet/
# since his example was written, the {{ }} syntax has become available for referring to dataframe columns
# so we see {{ }} here in place of his `enquo()`
# this assumes df is not already an `sf` object, just a dataframe or tbl.
longlat_to_sf <- function(df,
                           start_long = adep_long,
                           start_lat = adep_lat,
                           end_long = ades_long,
                           end_lat = ades_lat) {
  df %>%
    # {{ start_long }} selects the column referred to by the value of start_long (without quotes)
    select(
      {{ start_long }},
      {{ end_long }},
      {{ start_lat }},
      {{ end_lat }}
    ) %>%
    # make a list of lists, each of 4 numbers
    transpose() %>%
    # turn each list into a matrix
    map(~ matrix(flatten_dbl(.), nrow = 2)) %>%
    # feed that into st_linestring
    map(st_linestring) %>%
    st_sfc(crs = 4326) %>%
    st_sf(geometry = .)  %>% 
    rename(gc = geometry) %>%
    bind_cols(df) %>%
    relocate(gc, .after = {{ end_long }})
}

# compare the geography data that results - identical = TRUE
identical(
  long_sample %>% 
    rowwise() %>% # we want to have one line per row of data
    mutate(gc = st_linestring(matrix(c(adep_long, ades_long, adep_lat, ades_lat), 
                                     ncol = 2)) %>% 
             st_sfc(crs = 4326)) %>% 
    ungroup() %>% 
    pull(gc),
  long_sample %>% 
    longlat_to_sf()%>% 
    pull(gc)
)

# is it faster?
microbenchmark::microbenchmark(
  rowwise = long_sample %>% 
    rowwise() %>% # we want to have one line per row of data
    mutate(gc = st_linestring(matrix(c(adep_long, ades_long, adep_lat, ades_lat), 
                                     ncol = 2)) %>% 
             st_sfc(crs = 4326)) %>% 
    ungroup(),
  purrr = long_sample %>% 
    longlat_to_sf(),
  times = 10
)
```

### True Routes {#trueRoutes}

Now is the time to dip our toes into the route data from the R&D Data Archive. The files are large, so handle with care, but download `Flight_Points_Actual_20190301_20190331.csv.gz` into your `/data` directory, as you did the other files. This one has some 26 million rows, so we'll create a large sample to play with. In chapter [TBD] we'll see how to handle these datasets faster using datatables.

```{r, message = FALSE}
ac <- "AT72" # an aircraft type
# a sizeable sample
ac_flts <- flights %>% 
  filter(ac_type == ac)

# get the data
routes <- readr::read_csv("data/Flight_Points_Actual_20190301_20190331.csv.gz", skip = 1,
                          col_names = c("id", "seq", "time", "level", "lat", "long")) %>% 
  mutate(time = as.POSIXct(time, format = "%d-%m-%Y %H:%M:%S", tz = "UTC"))

routes %<>% filter(id %in% ac_flts$id) # reduce to a sample

save(routes, file = stringr::str_c("data/Flight_Points_Actual_201903_", ac, ".rda"))
```

Let's explore these data. Firstly by just plotting the points in the data and their flight level, we get a rapid picture of the airports from which these ATR turboprop aircraft operate.

```{r}
load("data/Flight_Points_Actual_201903_AT72.rda") # loads routes dataset

# convert in two steps
route_pts <- routes %>% 
  drop_na() %>% 
  st_as_sf(coords = c("long", "lat"), crs = 4326)

bounds <- get_bounds(route_pts) 
ggplot(route_pts) +
  geom_sf_bg() +
  geom_sf(aes(colour = level), size = 0.1, alpha = 0.7) +
  coord_sf(crs = crs_europe,
           xlim = c(bounds$xmin, bounds$xmax),
           ylim = c(bounds$ymin, bounds$ymax)) +
  theme_minimal() +
  labs(title = "Actual routes flown by AT72",
       colour = "Flight level",
       x="", y="") +
  scale_colour_viridis_b(direction = -1) 
```
This map gives a feel for the frequency at which the actual route is reported. It also shows some slightly odd-looking routing over the Atlantic (where radar coverage can be lacking).

For a more joined-up view, we need to convert the points into lines. The 'normal' approach to this is to `summarise` and then `st_cast`. But why does this work? Surely after `summarise` you only have group variables and variables created in the call (`time` and `level` in the example below)? Normally this is true. But the `geometry` column in an `sf` dataframe is 'sticky', and trumps this normal behaviour: summarising an `sf` silently summarises the geometry column into something sensible. In this case we get a 'multipoint' which we can then cast into a 'linestring'. 

So the overall sequence is: `st_as_sf` to get points, group, summarise, cast. There's one small twist: `summarise` normally involves a `union` operation which (unusually for R) _changes the data order_. So to keep the points in order we need to tell `summarise` to skip the union step.

```{r}
load("data/Flight_Points_Actual_201903_AT72.rda")

# convert in two steps
geo_routes <- routes %>% 
  drop_na() %>% 
  #use a 4D point
  st_as_sf(coords = c("long", "lat"), crs = 4326) %>% 
  # then 'summarise' into a linestring
  group_by(id) %>% 
  summarise(time = first(time),
            level = max(level), do_union = FALSE) %>% 
  st_cast("LINESTRING") %>% 
  # for this scale of map not really necessary, but segmentize anyway
 st_segmentize(units::set_units(0.5, degree))

bounds <- get_bounds(geo_routes) 
ggplot(geo_routes) +
  geom_sf_bg() +
  geom_sf(aes(colour = level), size = 0.2, alpha = 0.7) +
  coord_sf(crs = crs_europe,
           xlim = c(bounds$xmin, bounds$xmax),
           ylim = c(bounds$ymin, bounds$ymax)) +
  theme_minimal() +
  labs(title = "Actual routes flown by AT72",
       colour = "Max\nflight level",
       x="", y="") +
  scale_colour_viridis_b(direction = -1) 
```


### Exercises

#### Questions

1) Experiment with different colours, line thickness and transparency in the low-cost map.
2) In the low-cost map, take a larger sample of flights up to 1500km, and count the flights per airport pair. Colour the lines by traffic. Once ready, drop the sample completely, to give full counts for the month. Beware, some longitude or latitude might be missing, and such airport pairs need to be dropped.
3) Add labels for the top N (eg 20) airports in this extended low-cost map.
4) In the long-haul route map, why do some of the routes leave the map?
5) What's the solution to this?
6) When reducing routes to those for AT72 aircraft (start of section \@(trueRoutes)), we used a `filter`. With a big dataset, finding efficient code can save a lot of time. Is `filter` quicker or slower than using an `inner_join`?

#### Answers

1) Using `colour`, `size` and `alpha` parameters.
2) Something like this. We needed to drop airports with missing long-lat, using `drop_na`. It took a little work on the colouring, and line sizes to get something presentable. That includes sorting so that the busier routes get plotted last.

```{r}
lcc_counts <- flights %>% 
  # just short- or medium-haul lowcost
  filter(segment == "Lowcost" & dist_act_km <= 1500) %>% 
  drop_na() %>% # can't plot if we don't know the lat long of an AP 
  # slice_sample(n = 1000) %>% #just pick a few while debugging
  # count is a short-hand for group/summarise/ungroup
  count(adep, ades, adep_long, ades_long, adep_lat, ades_lat,
        name = "flts") %>% 
  rowwise() %>% # we want to have one line per row of data
  mutate(gc = st_linestring(matrix(c(adep_long, ades_long, adep_lat, ades_lat), ncol = 2)) %>% 
           st_sfc(crs = 4326)) %>% 
  ungroup() %>%
  arrange(flts) %>% 
  st_set_geometry("gc") 

#bounds doesn't mind if the sf geometry is points, lines, ... 
bounds <- get_bounds(lcc_counts) 
ggplot(lcc_counts) +
  geom_sf_bg() +
  geom_sf(aes(colour = flts), alpha = 0.4, size = 0.2)  +
  labs(title = "Low-cost routes", 
       colour = "Flights\nin the month") +
  coord_sf(crs = crs_europe,
           xlim = c(bounds$xmin, bounds$xmax),
           ylim = c(bounds$ymin, bounds$ymax)) +
  theme_minimal() +
  scale_colour_viridis_b(direction = -1)
```

3) See the extended exercises in chapter \@ref(sortbars) for an example of selecting top `n` and plotting deconflicted labels.
4) We're applying `bounds` to the data before segmenting. It seems to be a limitation of the `st_bbox` and `s2_bounds_rect` that they give the bounds of the vertices of lines (ie the points), not the line itself. 
5) An easy answer, though it increases the size of the dataset, is to move the `segmentize` to the end of the data preparation pipe. [Check that this works.]
6) You need something like this. Be patient with it. Looks like `join` takes 50%-100% longer, so we made the right choice.
```{r}
# get the data again 
routes <- readr::read_csv("data/Flight_Points_Actual_20190301_20190331.csv.gz", skip = 1,
                          col_names = c("id", "seq", "time", "level", "lat", "long")) %>% 
  mutate(time = as.POSIXct(time, format = "%d-%m-%Y %H:%M:%S", tz = "UTC"))

microbenchmark(
  use_in = routes  %>%  
    filter(id %in% ac_flts$id),
  use_join = routes  %>%  
    inner_join(ac_flts %>% select(id), by = "id"),
  times = 10
)
```


## Density of routes {#mapDensity}

We can get an approximate map of traffic density by picking points along the great circle routes (`st_segmentize`) at distances of, say, 75km and then counting (making a heatmap, with `geom_hex` from `ggplot2`) with a hex grid of the same size. It's not exact, since some routes might be counted twice in one hex (if they enter and leave through a vertex, say, rather than along the side). But it's relatively quick to do.

Compared to previous maps, the main differences are that we convert the lines into points with `st_cast('MULTIPOINT')`. This doesn't add points, it just extracts the vertices of the lines. And we break the rule and transform our data to the target CRS. From the result we extract the coordinates of every point, since this is the sort of data that `geom_hex` works with. I didn't find a way to get `geom_hex` to understand `sf` data directly, so we break the rule to work in 'plot coordinates' (which are x-y in metres when we use `crs_europe`).

We use both the `summarise` and the `purrr` method to speed up the calculation (see section \@ref(fasterGeo)), which on this machine is then acceptably quick for a 100,000 flight sample. If there's a way to pass a count of flights to `geom_hex`, I haven't found it, so we use `uncount` to reverse the `count` step.

```{r}
sample_km <- 60
flts <- set.seed(777) # to get a fixed, but random sample
short_points <- flights %>% 
  filter(dist_act_km <= 1500) %>% 
  drop_na() %>% 
  slice_sample(n = 100000) %>%  
  count(adep, ades, adep_long, ades_long, adep_lat, ades_lat,
        name = "flts") %>% 
  longlat_to_sf() %>%  #using our faster conversion function
  st_segmentize(units::set_units(sample_km, km)) 

bounds <- get_bounds(short_points) # quicker to get bounds now!

short_points <- short_points %>% 
  st_cast('MULTIPOINT') %>% 
  st_transform(crs_europe) %>% 
  uncount(flts) #duplicate by number of flights

just_pts <- st_coordinates(short_points)[ , 1:2] %>% 
  as_tibble()  

ggplot(just_pts) +
  geom_sf_bg() + 
  geom_hex(aes(X, Y), alpha = 0.7, 
           binwidth = sample_km * 1000) +
  coord_sf(crs = crs_europe,
           xlim = c(bounds$xmin, bounds$xmax),
           ylim = c(bounds$ymin, bounds$ymax))+
  theme_minimal() +
  labs(fill = "Flights\nin month",
       x="", y="") +
  scale_fill_viridis_c(direction = -1) 
```

To get a more precise density calculation we need to calculate explicitly which routes intersect which hexes. So we need some hexes. There's a promising package `dggridR` for doing this, but it's not available on CRAN at the time of writing, so we use a more fiddly approach that involves some functions in the `sp` package that we've more-or-less avoided using explicitly so far. The steps are:

1) Use the bounding box as the area in which we want hexes. Transform into planar coordinates and convert to a Spatial object
2) Sample points on a hexagonal grid.
3) Convert from points to hexagons.
4) Flip back to `sf` and then count the intersections. `st_intersects` lists the ids of hexes intersected, so we can just count. We intersect routes with hexes rather than the reverse because then we can just duplicate hex-ids (for each flight) rather than duplicating routes and doing more intersections.

This method is likely to struggle with global maps (because of wrapping problems), so better to focus on a single continent. It generates a couple of warnings ('discarded datum', 'comment ignored') which can be ignored (they're not shown in the book).

```{r warning=FALSE}
flts <- set.seed(777) # to get a fixed, but random sample
n_hex <- 10000 # this gives similar number to the 'geom_hex' version.
short_routes <- flights %>% 
  filter(dist_act_km <= 1500) %>% 
  drop_na() %>% 
  slice_sample(n = 100000) %>%
  count(adep, ades, adep_long, ades_long, adep_lat, ades_lat,
        name = "flts") %>% 
  longlat_to_sf() #using our faster conversion function
  # no segmentation
  
hex <- st_bbox(short_routes) %>% 
  st_as_sfc() %>% 
  st_transform(crs = crs_europe) %>% 
  as_Spatial() %>% 
  sp::spsample(n=n_hex, type = "hexagonal") %>% 
  sp::HexPoints2SpatialPolygons() %>% 
  st_as_sf() %>% 
  st_transform(crs = crs_europe) %>% 
  #optional: check areas are all equal
  # mutate(area = st_area(geometry)) %>% 
  rowid_to_column() # add id to each row, for later joining
  # but not for looping over - oh no!

hex_counts <- short_routes %>%
  st_transform(crs = crs_europe) %>% 
  st_intersects(hex) %>%
  # duplicate the hex ids, depending on the number of flights
  map2(short_routes$flts, rep) %>% 
  flatten_int() %>% #then collapse everything into a single vector
  as_tibble() %>% 
  count(value, name = "flts") #value is default name in as_tibble

# add in the counts to the hexes
hex <- hex %>%  
  left_join(hex_counts, by = c("rowid" = "value")) %>% 
  drop_na() # hexes with no traffic

bounds <- get_bounds(short_routes)
ggplot(hex) + 
  geom_sf_bg() + 
  geom_sf(aes(fill = flts), alpha = 0.7, size = 0)  +
  coord_sf(crs = crs_europe,
           xlim = c(bounds$xmin, bounds$xmax),
           ylim = c(bounds$ymin, bounds$ymax))+
  theme_minimal() +
  labs(fill = "Flights\nin month",
       x="", y="",
       caption = "Density is based on great-circle routing.") +
  scale_fill_viridis_c(direction = -1) 
```

Comparing the two version, the former has slightly smaller hexes (it's difficult to align the numbers precisely since one is defined by diameter and the other by number), but higher flight counts. This emphasises the reality of the overcounting risk: it would be better to drop the numbers from the scale, or use the second method!

If you extend to different samples, the process might fail, most likely because the hexes are spreading too wide. The solution is to crop more closely [adapt `get_bounds`, or the output from it to solve that] or use a hex-on-the-sphere approach such as in `dggridR` (https://github.com/r-barnes/dggridR/). 

### Exercises

#### Questions

1) Plot a density map of the AT72 routes, using the accurate intersection method.
2) AT72 are used in passenger, charter and all-cargo markets. Plot a density plot for each of these in separate facets. The facets are easy, but counting by `segment` as a group variable is quite tricky. If you want to try a simpler question: which four locations see most AT72 use on scheduled services?

#### Answers

1) Assuming that geo_routes is still in your environment, there are minor changes. Mostly because we don't need to count the flights, we assume that each route is unique. This is a much clearer picture of where the flights are most common.

```{r warning=FALSE}
# assume you still have geo_routes in your environment
n_hex <- 10000
hex <- st_bbox(geo_routes) %>% # just this line changes
  st_as_sfc() %>% 
  st_transform(crs = crs_europe) %>% 
  as_Spatial() %>% 
  sp::spsample(n=n_hex, type = "hexagonal") %>% 
  sp::HexPoints2SpatialPolygons() %>% 
  st_as_sf() %>% 
  st_transform(crs = crs_europe) %>% 
  rowid_to_column() 

hex_counts <- geo_routes %>%
  st_transform(crs = crs_europe) %>% 
  st_intersects(hex) %>%
  # duplicate the hex ids, depending on the number of flights
  flatten_int() %>% #then collapse everything into a single vector
  as_tibble() %>% 
  count(value, name = "flts") #value is default name in as_tibble

# add in the counts to the hexes
hex <- hex %>%  
  left_join(hex_counts, by = c("rowid" = "value")) %>% 
  drop_na() # hexes with no traffic

bounds <- get_bounds(geo_routes)
ggplot(hex %>% mutate(group = sample(1:2, n(), replace = TRUE))) + 
  geom_sf_bg() + 
  geom_sf(aes(fill = flts), alpha = 0.7, size = 0)  +
  coord_sf(crs = crs_europe,
           xlim = c(bounds$xmin, bounds$xmax),
           ylim = c(bounds$ymin, bounds$ymax))+
  theme_minimal() +
  labs(title = "ATR72 routes",
       fill = "Flights\nin month",
       x="", y="",
       caption = "Density is based on actual routing.") +
  scale_fill_viridis_c(direction = -1) 
```

2) This is a difficult one. We add the segments back into geo_routes, and pull out that column stand-alone. We hang on to `st_intersects` which is quick and is a sort of list so we use it as a tibble column. Then bind on the segments column, which gives our groups. At this point, we want one list or vector of hex-ids per segment so use `summarise` to collapse into a vector wrapped in a list so that it can also be a list column. And that can simply be `unnest`ed, ready for counting.  I'm happy to believe you might find an easier way to do this.

```{r warning=FALSE}
markets <- geo_routes %>% 
  # let's keep all segments for now
  left_join(ac_flts %>% select(id, segment)) %>% 
  pull(segment)

# the hexes can be the same as in Qn 1
n_hex <- 10000
hex <- st_bbox(geo_routes) %>% # just this line changes
  st_as_sfc() %>% 
  st_transform(crs = crs_europe) %>% 
  as_Spatial() %>% 
  sp::spsample(n=n_hex, type = "hexagonal") %>% 
  sp::HexPoints2SpatialPolygons() %>% 
  st_as_sf() %>% 
  st_transform(crs = crs_europe) %>% 
  rowid_to_column() 

hex_counts <- tibble(
    hex_id = st_intersects(geo_routes %>% 
                         st_transform(crs = crs_europe), 
                         hex),
    market = markets) %>% 
  group_by(market) %>% 
  summarise(hex_id = list(flatten_int(hex_id))) %>% 
  unnest(hex_id) %>% 
  count(market, hex_id, name = "flts")

# add in the counts to the hexes
hex_m <- hex %>%  
  left_join(hex_counts, by = c("rowid" = "hex_id")) %>% 
  drop_na() # hexes with no traffic

bounds <- get_bounds(geo_routes)
ggplot(hex_m) + 
  geom_sf_bg() + 
  geom_sf(aes(fill = flts), alpha = 0.7, size = 0)  +
  facet_wrap(~market) +
  coord_sf(crs = crs_europe,
           xlim = c(bounds$xmin, bounds$xmax),
           ylim = c(bounds$ymin, bounds$ymax))+
  theme_minimal() +
  labs(title = "ATR72 routes",
       fill = "Flights\nin month",
       x="", y="",
       caption = "Density is based on actual routing.") +
  scale_fill_viridis_c(direction = -1) 

```

## What has gone wrong?

With maps it seems that there are just so many things to get wrong. 

1) Map issues, especially polygons that seem to have crossings in them; errors like `Loop 96 is not valid: Edge 743 crosses edge 998`. This _could_ be that there is a problem in the map, but it can also be an awkward interaction between the map and a CRS especially at the 'dateline' (the 'far' edge of the map). There isn't a single solution to this, but filtering out chunks of the map that you don't need can work. In other cases, simplifying the map might help (`st_simplify`), in still others adding points can help(`st_segmentize`).
2) Empty maps, or maps with large empty areas. A map of Europe squeezed into the top right corner can mean that you've added a ggplot layer that is in long-lat to one that has been projected and is in metres (so that the long-lat get plotted somewhere near 0 long, 0 lat). You might also have a map that is being strict about including French Guiana and other overseas territories. In the first case, see the `coord_sf()` discussion earlier in this chapter. In the latter case, you'll need to set bounds for the map (see the later part of section \@ref(mapCountries)). 
3) In World maps, unexpected near-horizontal lines is a sign of cropping and dateline troubles. My usual solution is to use `himach::st_window`, which is basically a replacement for the `st_transform` that we've seen here that first cropps to the final view window. It's designed for use with the `crs_Atlantic` and `crs_Pacific` CRSs that come with the `himach` package. There are other functions for handling the 'dateline', but I haven't found an easier way to handle all types of geometry (line, polygon etc) so reliably.

```{r}
map <- rnaturalearthdata::coastline110 %>% 
  st_as_sf()

# a Pacific view creates problems along Greenwich meridian
ggplot(map) +
  geom_sf() +
  labs(title = "A map with wrapping problems at the 'far side'.") +
  coord_sf(crs = himach::crs_Pacific)

# st_window 
ggplot(map %>% himach::st_window(himach::crs_Pacific))+
  labs(title = "Wrapping problems solved.") +
  geom_sf()

```

```{r echo=FALSE}
rm(list = ls())
```

